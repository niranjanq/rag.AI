ğŸ“„ RAG with LangChain and Gemini - AI PDF Assistant
A Streamlit-based AI assistant that allows users to upload a PDF document and ask context-based questions about its content. The application uses LangChain, FAISS, HuggingFace embeddings, and Google Gemini to retrieve and generate accurate answers.

ğŸš€ Features
ğŸ“„ Upload any PDF file and extract text.

ğŸ” Split the PDF into manageable chunks using LangChain.

ğŸ§  Store and search chunks using FAISS Vector DB.

ğŸ¤– Use Google Gemini (Gemini 2.0 Flash) to generate answers from the most relevant context.

ğŸ’¬ Simple and intuitive Streamlit interface.

ğŸ› ï¸ Tech Stack
Streamlit

LangChain

FAISS

HuggingFace Transformers

Google Generative AI (Gemini)

ğŸ” Setup and Installation
Clone the repository:

bash
Copy
Edit
git clone https://github.com/your-username/ai-doc-assistant.git
cd ai-doc-assistant
Create and activate a virtual environment:

bash
Copy
Edit
python -m venv venv
source venv/bin/activate  # or venv\Scripts\activate on Windows
Install the dependencies:

bash
Copy
Edit
pip install -r requirements.txt
Set up your environment variables:

Create a .env file in the root directory and add your Gemini API key:

ini
Copy
Edit
GOOGLE-API-KEY=your_gemini_api_key
â–¶ï¸ Run the App
bash
Copy
Edit
streamlit run app.py
Open the app in your browser, upload a PDF, and start asking questions!

ğŸ“‚ Project Structure
bash
Copy
Edit
.
â”œâ”€â”€ app.py              # Main Streamlit app
â”œâ”€â”€ .env                # Environment variables (not committed)
â”œâ”€â”€ README.md           # Project documentation
â”œâ”€â”€ requirements.txt    # Python dependencies
âš ï¸ Limitations
Only supports text-based PDFs.

Works best with concise documents or well-structured reports.

Gemini output may vary slightly due to generative nature.

ğŸ™Œ Acknowledgements
Google Generative AI

HuggingFace for MiniLM embeddings

LangChain for streamlined RAG flow

Streamlit for easy UI development

ğŸ“¬ Contact
For questions or suggestions, reach out at [your-email@example.com]